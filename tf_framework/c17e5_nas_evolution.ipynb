{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe MIT License (MIT)\\nCopyright (c) 2021 NVIDIA\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\\nthe Software, and to permit persons to whom the Software is furnished to do so,\\nsubject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The MIT License (MIT)\n",
    "Copyright (c) 2021 NVIDIA\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "this software and associated documentation files (the \"Software\"), to deal in\n",
    "the Software without restriction, including without limitation the rights to\n",
    "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code example is very similar to c17e4_nas_random_hill, but it uses an evolutionary search algorithm instead of random search and hill climbing. More context for this code example can be found in the section \"Programming Example: Searching for an architecture for CIFAR-10 classification\" in Chapter 17 in the book Learning Deep Learning by Magnus Ekman (ISBN: 9780137470358).\n",
    "\n",
    "The initial part of the programming example is identical to c17e4_nas_random_hill with the addition of a constant POPULATION_SIZE which is used by the evolutionary algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import numpy as np\n",
    "import logging\n",
    "import copy\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "MAX_MODEL_SIZE = 500000\n",
    "CANDIDATE_EVALUATIONS = 500\n",
    "EVAL_EPOCHS = 3\n",
    "FINAL_EPOCHS = 20\n",
    "POPULATION_SIZE = 50\n",
    "\n",
    "layer_types = ['DENSE', 'CONV2D', 'MAXPOOL2D']\n",
    "param_values = dict([('size', [16, 64, 256, 1024, 4096]),\n",
    "                ('activation', ['relu', 'tanh', 'elu']),\n",
    "                ('kernel_size', [(1, 1), (2, 2), (3, 3), (4, 4)]),\n",
    "                ('stride', [(1, 1), (2, 2), (3, 3), (4, 4)]),\n",
    "                ('dropout', [0.0, 0.4, 0.7, 0.9])])\n",
    "\n",
    "layer_params = dict([('DENSE', ['size', 'activation', 'dropout']),\n",
    "                     ('CONV2D', ['size', 'activation',\n",
    "                                 'kernel_size', 'stride',\n",
    "                                 'dropout']),\n",
    "                     ('MAXPOOL2D', ['kernel_size', 'stride',\n",
    "                                    'dropout'])])\n",
    "\n",
    "# Load dataset.\n",
    "cifar_dataset = keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images,\n",
    "                    test_labels) = cifar_dataset.load_data()\n",
    "\n",
    "# Standardize dataset.\n",
    "mean = np.mean(train_images)\n",
    "stddev = np.std(train_images)\n",
    "train_images = (train_images - mean) / stddev\n",
    "test_images = (test_images - mean) / stddev\n",
    "\n",
    "# Change labels to one-hot.\n",
    "train_labels = to_categorical(train_labels,\n",
    "                              num_classes=10)\n",
    "test_labels = to_categorical(test_labels,\n",
    "                             num_classes=10)\n",
    "\n",
    "# Methods to create a model definition.\n",
    "def generate_random_layer(layer_type):\n",
    "    layer = {}\n",
    "    layer['layer_type'] = layer_type\n",
    "    params = layer_params[layer_type]\n",
    "    for param in params:\n",
    "        values = param_values[param]\n",
    "        layer[param] = values[np.random.randint(0, len(values))]\n",
    "    return layer\n",
    "\n",
    "def generate_model_definition():\n",
    "    layer_count = np.random.randint(2, 9)\n",
    "    non_dense_count = np.random.randint(1, layer_count)\n",
    "    layers = []\n",
    "    for i in range(layer_count):\n",
    "        if i < non_dense_count:\n",
    "            layer_type = layer_types[np.random.randint(1, 3)]\n",
    "            layer = generate_random_layer(layer_type)\n",
    "        else:\n",
    "            layer = generate_random_layer('DENSE')\n",
    "        layers.append(layer)\n",
    "    return layers\n",
    "\n",
    "def compute_weight_count(layers):\n",
    "    last_shape = (32, 32, 3)\n",
    "    total_weights = 0\n",
    "    for layer in layers:\n",
    "        layer_type = layer['layer_type']\n",
    "        if layer_type == 'DENSE':\n",
    "            size = layer['size']\n",
    "            weights = size * (np.prod(last_shape) + 1)\n",
    "            last_shape = (layer['size'])\n",
    "        else:\n",
    "            stride = layer['stride']\n",
    "            if layer_type == 'CONV2D':\n",
    "                size = layer['size']\n",
    "                kernel_size = layer['kernel_size']\n",
    "                weights = size * ((np.prod(kernel_size) *\n",
    "                                   last_shape[2]) + 1)\n",
    "                last_shape = (np.ceil(last_shape[0]/stride[0]),\n",
    "                              np.ceil(last_shape[1]/stride[1]),\n",
    "                              size)\n",
    "            elif layer_type == 'MAXPOOL2D':\n",
    "                weights = 0\n",
    "                last_shape = (np.ceil(last_shape[0]/stride[0]),\n",
    "                              np.ceil(last_shape[1]/stride[1]),\n",
    "                              last_shape[2])\n",
    "        total_weights += weights\n",
    "    total_weights += ((np.prod(last_shape) + 1) * 10)\n",
    "    return total_weights\n",
    "\n",
    "# Methods to create and evaluate model based on model definition.\n",
    "def add_layer(model, params, prior_type):\n",
    "    layer_type = params['layer_type']\n",
    "    if layer_type == 'DENSE':\n",
    "        if prior_type != 'DENSE':\n",
    "            model.add(Flatten())\n",
    "        size = params['size']\n",
    "        act = params['activation']\n",
    "        model.add(Dense(size, activation=act))\n",
    "    elif layer_type == 'CONV2D':\n",
    "        size = params['size']\n",
    "        act = params['activation']\n",
    "        kernel_size = params['kernel_size']\n",
    "        stride = params['stride']\n",
    "        model.add(Conv2D(size, kernel_size, activation=act,\n",
    "                         strides=stride, padding='same'))\n",
    "    elif layer_type == 'MAXPOOL2D':\n",
    "        kernel_size = params['kernel_size']\n",
    "        stride = params['stride']\n",
    "        model.add(MaxPooling2D(pool_size=kernel_size,\n",
    "                               strides=stride, padding='same'))\n",
    "    dropout = params['dropout']\n",
    "    if(dropout > 0.0):\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "def create_model(layers):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x, input_shape=(32, 32, 3)))\n",
    "    prev_layer = 'LAMBDA' # Dummy layer to set input_shape\n",
    "    for layer in layers:\n",
    "        add_layer(model, layer, prev_layer)\n",
    "        prev_layer = layer['layer_type']\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_and_evaluate_model(model_definition):\n",
    "    weight_count = compute_weight_count(model_definition)\n",
    "    if weight_count > MAX_MODEL_SIZE:\n",
    "        return 0.0\n",
    "    model = create_model(model_definition)\n",
    "    history = model.fit(train_images, train_labels,\n",
    "                        validation_data=(test_images, test_labels),\n",
    "                        epochs=EVAL_EPOCHS, batch_size=64,\n",
    "                        verbose=2, shuffle=False)\n",
    "    acc = history.history['val_accuracy'][-1]\n",
    "    print('Size: ', weight_count)\n",
    "    print('Accuracy: %5.2f' %acc)\n",
    "    return acc\n",
    "\n",
    "# Helper method for hill climbing and evolutionary algorithm.\n",
    "def tweak_model(model_definition):\n",
    "    layer_num = np.random.randint(0, len(model_definition))\n",
    "    last_layer = len(model_definition) - 1\n",
    "    for first_dense, layer in enumerate(model_definition):\n",
    "        if layer['layer_type'] == 'DENSE':\n",
    "            break\n",
    "    if np.random.randint(0, 2) == 1:\n",
    "        delta = 1\n",
    "    else:\n",
    "        delta = -1\n",
    "    if np.random.randint(0, 2) == 1:\n",
    "        # Add/remove layer.\n",
    "        if len(model_definition) < 3:\n",
    "            delta = 1 # Layer removal not allowed\n",
    "        if delta == -1:\n",
    "            # Remove layer.\n",
    "            if layer_num == 0 and first_dense == 1:\n",
    "                layer_num += 1 # Require >= 1 non-dense layer\n",
    "            if layer_num == first_dense and layer_num == last_layer:\n",
    "                layer_num -= 1 # Require >= 1 dense layer\n",
    "            del model_definition[layer_num]\n",
    "        else:\n",
    "            # Add layer.\n",
    "            if layer_num < first_dense:\n",
    "                layer_type = layer_types[np.random.randint(1, 3)]\n",
    "            else:\n",
    "                layer_type = 'DENSE'\n",
    "            layer = generate_random_layer(layer_type)\n",
    "            model_definition.insert(layer_num, layer)\n",
    "    else:\n",
    "        # Tweak parameter.\n",
    "        layer = model_definition[layer_num]\n",
    "        layer_type = layer['layer_type']\n",
    "        params = layer_params[layer_type]\n",
    "        param = params[np.random.randint(0, len(params))]\n",
    "        current_val = layer[param]\n",
    "        values = param_values[param]\n",
    "        index = values.index(current_val)\n",
    "        max_index = len(values)\n",
    "        new_val = values[(index + delta) % max_index]\n",
    "        layer[param] = new_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key part of the evolutionary algorithm is the crossover operation, which combines two existing solutions (parents) into a new solution (child) that inherits properties of both of its parents. It is implemented in the code snippet below (see book for more details).\n",
    "\n",
    "The evolutionary algorithm starts by generating and evaluating a population of random models. It then randomly generates new models by tweaking and combining models in the existing population. There are three ways that a new model can be created:\n",
    "- Tweak an existing model.\n",
    "- Combine two parent models into a child model.\n",
    "- Combine two parent models into a child model and apply a tweak to the resulting model.\n",
    "\n",
    "Once new models have been generated, the algorithm probabilistically selects high-performing models to keep for the next iteration. In this selection process, both the parents and the children participate, which is also known as elitism within the field of evolutionary computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Population Model 1 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 7s - loss: 3.0955 - accuracy: 0.1101 - val_loss: 2.1464 - val_accuracy: 0.1729\n",
      "Epoch 2/3\n",
      "782/782 - 6s - loss: 2.3507 - accuracy: 0.1332 - val_loss: 2.0911 - val_accuracy: 0.1906\n",
      "Epoch 3/3\n",
      "782/782 - 6s - loss: 2.3034 - accuracy: 0.1429 - val_loss: 2.0692 - val_accuracy: 0.2051\n",
      "Size:  306570.0\n",
      "Accuracy:  0.21\n",
      "\n",
      "Population Model 2 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 33s - loss: 2.4486 - accuracy: 0.1008 - val_loss: 2.3272 - val_accuracy: 0.1000\n",
      "Epoch 2/3\n",
      "782/782 - 37s - loss: 2.4060 - accuracy: 0.1005 - val_loss: 2.3220 - val_accuracy: 0.1000\n",
      "Epoch 3/3\n",
      "782/782 - 39s - loss: 2.4154 - accuracy: 0.1008 - val_loss: 2.3258 - val_accuracy: 0.1000\n",
      "Size:  154650.0\n",
      "Accuracy:  0.10\n",
      "\n",
      "Population Model 3 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 9s - loss: 2.4896 - accuracy: 0.1081 - val_loss: 2.2895 - val_accuracy: 0.1183\n",
      "Epoch 2/3\n",
      "782/782 - 8s - loss: 2.2962 - accuracy: 0.1213 - val_loss: 2.2647 - val_accuracy: 0.1168\n",
      "Epoch 3/3\n",
      "782/782 - 8s - loss: 2.2880 - accuracy: 0.1289 - val_loss: 2.2810 - val_accuracy: 0.1031\n",
      "Size:  310746.0\n",
      "Accuracy:  0.10\n",
      "\n",
      "Population Model 4 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 6s - loss: 2.3320 - accuracy: 0.1054 - val_loss: 2.2933 - val_accuracy: 0.1109\n",
      "Epoch 2/3\n",
      "782/782 - 5s - loss: 2.3060 - accuracy: 0.1157 - val_loss: 2.2275 - val_accuracy: 0.1564\n",
      "Epoch 3/3\n",
      "782/782 - 5s - loss: 2.2852 - accuracy: 0.1264 - val_loss: 2.2247 - val_accuracy: 0.1658\n",
      "Size:  50026.0\n",
      "Accuracy:  0.17\n",
      "\n",
      "Population Model 5 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 9s - loss: 2.5066 - accuracy: 0.1006 - val_loss: 2.2959 - val_accuracy: 0.1099\n",
      "Epoch 2/3\n",
      "782/782 - 8s - loss: 2.4553 - accuracy: 0.1039 - val_loss: 2.2999 - val_accuracy: 0.1002\n",
      "Epoch 3/3\n",
      "782/782 - 8s - loss: 2.3754 - accuracy: 0.1067 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Size:  121882.0\n",
      "Accuracy:  0.10\n",
      "\n",
      "Population Model 6 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 7s - loss: 1.9913 - accuracy: 0.2886 - val_loss: 1.7502 - val_accuracy: 0.3736\n",
      "Epoch 2/3\n",
      "782/782 - 6s - loss: 1.8561 - accuracy: 0.3353 - val_loss: 1.6979 - val_accuracy: 0.3940\n",
      "Epoch 3/3\n",
      "782/782 - 6s - loss: 1.8215 - accuracy: 0.3502 - val_loss: 1.6637 - val_accuracy: 0.4101\n",
      "Size:  438986.0\n",
      "Accuracy:  0.41\n",
      "\n",
      "Population Model 7 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 14s - loss: 2.5246 - accuracy: 0.1281 - val_loss: 2.2542 - val_accuracy: 0.1684\n",
      "Epoch 2/3\n",
      "782/782 - 13s - loss: 2.4324 - accuracy: 0.1354 - val_loss: 2.2328 - val_accuracy: 0.1527\n",
      "Epoch 3/3\n",
      "782/782 - 13s - loss: 2.4020 - accuracy: 0.1376 - val_loss: 2.2299 - val_accuracy: 0.1694\n",
      "Size:  155658.0\n",
      "Accuracy:  0.17\n",
      "\n",
      "Population Model 8 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 7s - loss: 2.1104 - accuracy: 0.2337 - val_loss: 1.8493 - val_accuracy: 0.3482\n",
      "Epoch 2/3\n",
      "782/782 - 6s - loss: 1.9539 - accuracy: 0.2896 - val_loss: 1.7718 - val_accuracy: 0.3688\n",
      "Epoch 3/3\n",
      "782/782 - 6s - loss: 1.9067 - accuracy: 0.3130 - val_loss: 1.7327 - val_accuracy: 0.3898\n",
      "Size:  214474.0\n",
      "Accuracy:  0.39\n",
      "\n",
      "Population Model 9 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 8s - loss: 4.7009 - accuracy: 0.1039 - val_loss: 2.3106 - val_accuracy: 0.0847\n",
      "Epoch 2/3\n",
      "782/782 - 7s - loss: 2.3708 - accuracy: 0.1093 - val_loss: 2.2909 - val_accuracy: 0.1297\n",
      "Epoch 3/3\n",
      "782/782 - 6s - loss: 2.3152 - accuracy: 0.1123 - val_loss: 2.2843 - val_accuracy: 0.1472\n",
      "Size:  954.0\n",
      "Accuracy:  0.15\n",
      "\n",
      "Population Model 10 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 21s - loss: 2.2162 - accuracy: 0.1570 - val_loss: 2.0244 - val_accuracy: 0.2314\n",
      "Epoch 2/3\n",
      "782/782 - 20s - loss: 2.1198 - accuracy: 0.1915 - val_loss: 1.9762 - val_accuracy: 0.2602\n",
      "Epoch 3/3\n",
      "782/782 - 18s - loss: 2.0895 - accuracy: 0.2022 - val_loss: 1.9451 - val_accuracy: 0.2662\n",
      "Size:  435866.0\n",
      "Accuracy:  0.27\n",
      "\n",
      "Population Model 11 out of 50\n",
      "Epoch 1/3\n",
      "782/782 - 17s - loss: 2.1478 - accuracy: 0.1994 - val_loss: 2.0425 - val_accuracy: 0.2311\n",
      "Epoch 2/3\n",
      "782/782 - 16s - loss: 2.0865 - accuracy: 0.2215 - val_loss: 2.0249 - val_accuracy: 0.2441\n",
      "Epoch 3/3\n",
      "782/782 - 17s - loss: 2.0626 - accuracy: 0.2322 - val_loss: 1.9924 - val_accuracy: 0.2559\n",
      "Size:  375946.0\n",
      "Accuracy:  0.26\n",
      "\n",
      "Population Model 12 out of 50\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10264/2446254799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_model\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mmodel_definition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_model_definition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_and_evaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_definition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mvalid_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10264/1317724995.py\u001b[0m in \u001b[0;36mcreate_and_evaluate_model\u001b[1;34m(model_definition)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_definition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     history = model.fit(train_images, train_labels,\n\u001b[0m\u001b[0;32m    148\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEVAL_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Helper method for evolutionary algorithm.\n",
    "def cross_over(parents):\n",
    "    # Pick bottom half of one and top half of the other.\n",
    "    # If model is small, randomly stack top or bottom from both.\n",
    "    bottoms = [[], []]\n",
    "    tops = [[], []]\n",
    "    for i, model in enumerate(parents):\n",
    "        for layer in model:\n",
    "            if layer['layer_type'] != 'DENSE':\n",
    "                bottoms[i].append(copy.deepcopy(layer))\n",
    "            else:\n",
    "                tops[i].append(copy.deepcopy(layer))\n",
    "\n",
    "    i = np.random.randint(0, 2)\n",
    "    if (i == 1 and compute_weight_count(parents[0]) +\n",
    "        compute_weight_count(parents[1]) < MAX_MODEL_SIZE):\n",
    "        i = np.random.randint(0, 2)\n",
    "        new_model = bottoms[i] + bottoms[(i+1)%2]\n",
    "        i = np.random.randint(0, 2)\n",
    "        new_model = new_model + tops[i] + tops[(i+1)%2]\n",
    "    else:\n",
    "        i = np.random.randint(0, 2)\n",
    "        new_model = bottoms[i] + tops[(i+1)%2]\n",
    "    return new_model\n",
    "\n",
    "# Evolutionary algorithm.\n",
    "np.random.seed(7)\n",
    "\n",
    "# Generate initial population of models.\n",
    "population = []\n",
    "for i in range(POPULATION_SIZE):\n",
    "    print(f'\\nPopulation Model {i + 1} out of {POPULATION_SIZE}')\n",
    "    valid_model = False\n",
    "    while(valid_model == False):\n",
    "        model_definition = generate_model_definition()\n",
    "        acc = create_and_evaluate_model(model_definition)\n",
    "        if acc > 0.0:\n",
    "            valid_model = True\n",
    "    population.append((acc, model_definition))\n",
    "\n",
    "# Evolve population.\n",
    "generations = int(CANDIDATE_EVALUATIONS / POPULATION_SIZE) - 1\n",
    "for i in range(generations):\n",
    "    # Generate new individuals.\n",
    "    print('Generation number: ', i)\n",
    "    for j in range(POPULATION_SIZE):\n",
    "        valid_model = False\n",
    "        while(valid_model == False):\n",
    "            rand = np.random.rand()\n",
    "            parents = np.random.sample(\n",
    "                population[:POPULATION_SIZE], 2)\n",
    "            parents = [parents[0][1], parents[1][1]]\n",
    "            if rand < 0.5:\n",
    "                child = copy.deepcopy(parents[0])\n",
    "                tweak_model(child)\n",
    "            elif rand < 0.75:\n",
    "                child = cross_over(parents)\n",
    "            else:\n",
    "                child = cross_over(parents)\n",
    "                tweak_model(child)\n",
    "            acc = create_and_evaluate_model(child)\n",
    "            if acc > 0.0:\n",
    "                valid_model = True\n",
    "        population.append((acc, child))\n",
    "    # Randomly select fit individuals.\n",
    "    population.sort(key=lambda x:x[0])\n",
    "    print('Evolution, best accuracy: %5.2f' %population[-1][0])\n",
    "    top = np.int(np.ceil(0.2*len(population)))\n",
    "    bottom = np.int(np.ceil(0.3*len(population)))\n",
    "    top_individuals = population[-top:]\n",
    "    remaining = np.int(len(population)/2) - len(top_individuals)\n",
    "    population = np.random.sample(population[bottom:-top],\n",
    "                               remaining) + top_individuals\n",
    "\n",
    "best_model = population[-1][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for c17e4_nas_random_hill, we conclude with evaluating the best model for a larger number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model for larger number of epochs.\n",
    "model = create_model(best_model)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_images, train_labels, validation_data =\n",
    "    (test_images, test_labels), epochs=FINAL_EPOCHS, batch_size=64,\n",
    "    verbose=2, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de70ba1dfedd7665bf4cd0ee86c8db35b01ecbb5c479dd9bcdca1245d2c3a48c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
